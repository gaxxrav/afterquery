#!/usr/bin/env python3
"""
Comprehensive test suite for CSV Data Processing Pipeline
Tests all four reports generated by solution.sh for correctness and format consistency
"""

import os
import re
import subprocess
import pytest
from pathlib import Path


class TestCSVPipeline:
    """Test suite for CSV Data Processing Pipeline"""
    
    @classmethod
    def setup_class(cls):
        """Setup test environment and run solution if needed"""
        cls.reports_dir = Path("reports")
        cls.data_dir = Path("data")
        
        # Ensure solution has been run
        if not cls.reports_dir.exists() or not any(cls.reports_dir.glob("*.txt")):
            print("Running solution.sh to generate reports...")
            result = subprocess.run(["./solution.sh"], capture_output=True, text=True)
            if result.returncode != 0:
                pytest.fail(f"Solution script failed: {result.stderr}")
        
        # Load report contents
        cls.top_performers = cls._load_report("top_performers.txt")
        cls.department_analysis = cls._load_report("department_analysis.txt")
        cls.trend_analysis = cls._load_report("trend_analysis.txt")
        cls.data_quality = cls._load_report("data_quality.txt")
    
    @classmethod
    def _load_report(cls, filename):
        """Load report content from file"""
        report_path = cls.reports_dir / filename
        if not report_path.exists():
            pytest.fail(f"Report file not found: {filename}")
        
        with open(report_path, 'r') as f:
            return f.read()
    
    def test_top_sales_reps_by_revenue(self):
        """Test 1: Verify correct revenue calculations and ranking for top sales reps"""
        # Check that top performers report exists and has expected structure
        assert "TOP 5 SALES REPS BY TOTAL REVENUE" in self.top_performers
        
        # Extract revenue section
        revenue_section = re.search(
            r"TOP 5 SALES REPS BY TOTAL REVENUE:.*?\n(.*?)(?=\n\n|\nTOP 5 SALES REPS BY NUMBER OF DEALS|$)",
            self.top_performers,
            re.DOTALL
        )
        assert revenue_section, "Revenue section not found in report"
        
        # Parse revenue data
        revenue_lines = [line.strip() for line in revenue_section.group(1).split('\n') 
                        if line.strip() and not line.startswith('=')]
        
        # Should have exactly 5 entries
        assert len(revenue_lines) >= 3, f"Expected at least 3 revenue entries, got {len(revenue_lines)}"
        
        # Verify format and descending order
        prev_revenue = float('inf')
        for line in revenue_lines[:5]:  # Check top 5
            # Extract revenue amount (format: "1002: $123,456.78 (X deals)")
            revenue_match = re.search(r'\$([0-9,]+\.[0-9]{2})', line)
            assert revenue_match, f"Invalid revenue format in line: {line}"
            
            current_revenue = float(revenue_match.group(1).replace(',', ''))
            assert current_revenue <= prev_revenue, f"Revenue not in descending order: {line}"
            prev_revenue = current_revenue
            
            # Verify deal count is present
            assert re.search(r'\(\d+ deals\)', line), f"Deal count missing in line: {line}"
    
    def test_department_salary_averages(self):
        """Test 2: Check mathematical accuracy of department salary averages"""
        assert "AVERAGE SALARY BY DEPARTMENT" in self.department_analysis
        
        # Extract salary averages section
        salary_section = re.search(
            r"AVERAGE SALARY BY DEPARTMENT:.*?\n(.*?)(?=\n\n|$)",
            self.department_analysis,
            re.DOTALL
        )
        assert salary_section, "Salary averages section not found"
        
        # Parse salary data
        salary_lines = [line.strip() for line in salary_section.group(1).split('\n') 
                       if line.strip() and not line.startswith('=')]
        
        # Should have multiple departments
        assert len(salary_lines) >= 3, f"Expected at least 3 departments, got {len(salary_lines)}"
        
        # Verify format and reasonable salary ranges
        for line in salary_lines:
            # Format: "Engineering: $95,000.00"
            salary_match = re.search(r'([A-Za-z]+)\s*:\s*\$([0-9,]+\.[0-9]{2})', line)
            assert salary_match, f"Invalid salary format in line: {line}"
            
            dept_name = salary_match.group(1)
            salary = float(salary_match.group(2).replace(',', ''))
            
            # Reasonable salary range check
            assert 50000 <= salary <= 150000, f"Unrealistic salary for {dept_name}: ${salary:,.2f}"
    
    def test_missing_data_detection(self):
        """Test 3: Edge case handling for empty/null fields"""
        assert "MISSING DATA ANALYSIS" in self.data_quality
        
        # Check that all file types are analyzed
        assert "Employees File:" in self.data_quality
        assert "Sales Q1 File:" in self.data_quality
        assert "Sales Q2 File:" in self.data_quality
        assert "Server Metrics File:" in self.data_quality
        
        # Extract missing data counts
        missing_patterns = [
            r"Missing names:\s*(\d+)",
            r"Missing departments:\s*(\d+)",
            r"Missing salaries:\s*(\d+)",
            r"Missing employee IDs:\s*(\d+)",
            r"Missing amounts:\s*(\d+)"
        ]
        
        for pattern in missing_patterns:
            matches = re.findall(pattern, self.data_quality)
            assert len(matches) >= 1, f"Missing data pattern not found: {pattern}"
            
            # Verify counts are reasonable (should detect the edge cases we added)
            for count in matches:
                assert 0 <= int(count) <= 50, f"Unrealistic missing data count: {count}"
    
    def test_duplicate_transaction_removal(self):
        """Test 4: Data quality validation for duplicate records"""
        assert "DUPLICATE RECORDS" in self.data_quality
        
        # Should detect duplicate transactions
        duplicate_section = re.search(
            r"DUPLICATE RECORDS:.*?\n(.*?)(?=\n\n|DATA VALIDATION|$)",
            self.data_quality,
            re.DOTALL
        )
        assert duplicate_section, "Duplicate records section not found"
        
        # Check for duplicate transaction detection
        duplicate_text = duplicate_section.group(1)
        assert "transaction_id" in duplicate_text.lower() or "duplicate" in duplicate_text.lower()
        
        # Should identify the T001 and T147 duplicates we added
        duplicate_matches = re.findall(r'T\d+:\s*(\d+)\s*occurrences', duplicate_text)
        if duplicate_matches:
            for count in duplicate_matches:
                assert int(count) >= 2, f"Duplicate count should be >= 2, got {count}"
    
    def test_monthly_trend_analysis(self):
        """Test 5: Date parsing and grouping accuracy for monthly trends"""
        assert "MONTHLY SALES TRENDS" in self.trend_analysis
        
        # Extract monthly trends section
        trends_section = re.search(
            r"MONTHLY SALES TRENDS:.*?\n(.*?)(?=\n\n|REGIONAL PERFORMANCE|$)",
            self.trend_analysis,
            re.DOTALL
        )
        assert trends_section, "Monthly trends section not found"
        
        # Parse monthly data
        trends_text = trends_section.group(1)
        month_lines = [line.strip() for line in trends_text.split('\n') 
                      if re.match(r'^\d{4}-\d{2}', line.strip())]
        
        # Should have multiple months (Q1 and Q2 data)
        assert len(month_lines) >= 3, f"Expected at least 3 months, got {len(month_lines)}"
        
        # Verify month format and chronological order
        prev_month = "0000-00"
        for line in month_lines:
            month_match = re.match(r'^(\d{4}-\d{2})', line)
            assert month_match, f"Invalid month format in line: {line}"
            
            current_month = month_match.group(1)
            assert current_month > prev_month, f"Months not in chronological order: {line}"
            prev_month = current_month
            
            # Verify revenue and deal count format
            assert re.search(r'\$[0-9,]+\.[0-9]{2}', line), f"Revenue format invalid: {line}"
            assert re.search(r'\(\d+ deals\)', line), f"Deal count format invalid: {line}"
    
    def test_output_format_consistency(self):
        """Test 6: Ensure standardized report format across all outputs"""
        reports = [
            ("top_performers.txt", self.top_performers),
            ("department_analysis.txt", self.department_analysis),
            ("trend_analysis.txt", self.trend_analysis),
            ("data_quality.txt", self.data_quality)
        ]
        
        for filename, content in reports:
            # Check header format
            assert "=" * 40 in content, f"Missing header separator in {filename}"
            assert "REPORT" in content.upper(), f"Missing 'REPORT' in header of {filename}"
            
            # Check timestamp
            assert re.search(r"Generated on: \d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}", content), \
                   f"Missing or invalid timestamp in {filename}"
            
            # Check section separators
            section_count = len(re.findall(r'^[A-Z][A-Z\s]+:$', content, re.MULTILINE))
            assert section_count >= 2, f"Insufficient sections in {filename}"
            
            # Verify no empty sections
            lines = content.split('\n')
            for i, line in enumerate(lines):
                if line.endswith(':') and line.isupper():
                    # Check that section has content
                    next_lines = lines[i+1:i+10]  # Check next 10 lines
                    has_content = any(line.strip() and not line.startswith('=') 
                                    for line in next_lines)
                    assert has_content, f"Empty section found in {filename}: {line}"
    
    def test_server_performance_outliers(self):
        """Test 7: Statistical analysis accuracy for server performance"""
        assert "SERVER PERFORMANCE OUTLIERS" in self.trend_analysis
        
        # Extract server outliers section
        outliers_section = re.search(
            r"SERVER PERFORMANCE OUTLIERS:.*?\n(.*?)$",
            self.trend_analysis,
            re.DOTALL
        )
        assert outliers_section, "Server outliers section not found"
        
        outliers_text = outliers_section.group(1)
        
        # Check for high CPU usage detection
        assert "High CPU Usage" in outliers_text
        cpu_outliers = re.findall(r'(\w+-\d+).*?(\d+\.\d+)% CPU', outliers_text)
        
        # Verify CPU outliers are actually > 90%
        for server, cpu_pct in cpu_outliers:
            cpu_value = float(cpu_pct)
            assert cpu_value > 90, f"CPU outlier {server} has {cpu_value}% which is not > 90%"
        
        # Check for high memory usage detection
        assert "High Memory Usage" in outliers_text
        memory_outliers = re.findall(r'(\w+-\d+).*?(\d+\.\d+)% Memory', outliers_text)
        
        # Verify memory outliers are actually > 90%
        for server, mem_pct in memory_outliers:
            mem_value = float(mem_pct)
            assert mem_value > 90, f"Memory outlier {server} has {mem_value}% which is not > 90%"
        
        # Check for critical status servers
        assert "Critical Status Servers" in outliers_text
        critical_servers = re.findall(r'(\w+-\d+).*?critical', outliers_text, re.IGNORECASE)
        
        # Should find the critical servers we added in test data
        assert len(critical_servers) >= 1, "No critical status servers detected"
    
    def test_regional_performance_comparison(self):
        """Test 8: Regional analysis accuracy and completeness"""
        assert "REGIONAL PERFORMANCE COMPARISON" in self.trend_analysis
        
        # Extract regional performance section
        regional_section = re.search(
            r"REGIONAL PERFORMANCE COMPARISON:.*?\n(.*?)(?=\n\n|SERVER PERFORMANCE|$)",
            self.trend_analysis,
            re.DOTALL
        )
        assert regional_section, "Regional performance section not found"
        
        regional_text = regional_section.group(1)
        
        # Should have header row
        assert "Region" in regional_text and "Total Revenue" in regional_text
        
        # Parse regional data rows
        data_lines = [line.strip() for line in regional_text.split('\n') 
                     if line.strip() and not line.startswith('-') and 
                     not 'Region' in line and not '=' in line]
        
        # Should have all 4 regions (North, South, East, West)
        regions_found = set()
        total_market_pct = 0
        
        for line in data_lines:
            # Format: "North    $123,456.78      45 $2,743.71   25.5%"
            region_match = re.match(r'^(\w+)', line)
            if region_match:
                region = region_match.group(1)
                regions_found.add(region)
                
                # Extract market percentage
                pct_match = re.search(r'(\d+\.\d+)%', line)
                if pct_match:
                    total_market_pct += float(pct_match.group(1))
        
        # Should have multiple regions
        assert len(regions_found) >= 3, f"Expected at least 3 regions, found: {regions_found}"
        
        # Market percentages should sum to approximately 100%
        assert 95 <= total_market_pct <= 105, f"Market percentages sum to {total_market_pct}%, expected ~100%"
    
    def test_data_validation_comprehensive(self):
        """Test 9: Comprehensive data validation and error detection"""
        assert "DATA VALIDATION ISSUES" in self.data_quality
        
        # Extract validation section
        validation_section = re.search(
            r"DATA VALIDATION ISSUES:.*?\n(.*?)(?=\n\n|SUMMARY STATISTICS|$)",
            self.data_quality,
            re.DOTALL
        )
        assert validation_section, "Data validation section not found"
        
        validation_text = validation_section.group(1)
        
        # Should detect invalid dates
        assert "Invalid dates:" in validation_text
        
        # Should detect negative amounts (we added some in test data)
        assert "Negative amounts:" in validation_text
        
        # Should detect invalid numeric values
        assert "Invalid numeric values:" in validation_text
        
        # Verify specific edge cases are caught
        edge_cases_detected = 0
        
        # Check for specific invalid entries we added
        if "2021-13-40" in validation_text:  # Invalid month
            edge_cases_detected += 1
        if "2024-02-30" in validation_text:  # Invalid date
            edge_cases_detected += 1
        if "2024-06-31" in validation_text:  # Invalid date
            edge_cases_detected += 1
        if "-2500" in validation_text or "-3500" in validation_text:  # Negative amounts
            edge_cases_detected += 1
        
        assert edge_cases_detected >= 2, f"Expected to detect at least 2 edge cases, found {edge_cases_detected}"
    
    def test_summary_statistics_accuracy(self):
        """Test 10: Overall summary statistics and data quality metrics"""
        assert "SUMMARY STATISTICS" in self.data_quality
        
        # Extract summary section
        summary_section = re.search(
            r"SUMMARY STATISTICS:.*?\n(.*?)$",
            self.data_quality,
            re.DOTALL
        )
        assert summary_section, "Summary statistics section not found"
        
        summary_text = summary_section.group(1)
        
        # Should have total records count
        total_match = re.search(r"Total records processed:\s*(\d+)", summary_text)
        assert total_match, "Total records count not found"
        total_records = int(total_match.group(1))
        assert total_records > 400, f"Expected > 400 total records, got {total_records}"
        
        # Should have validity percentages for each file type
        validity_patterns = [
            r"Valid employee records:\s*(\d+)\s*/\s*(\d+)\s*\(([0-9.]+)%\)",
            r"Valid sales records:\s*(\d+)\s*/\s*(\d+)\s*\(([0-9.]+)%\)",
            r"Valid server records:\s*(\d+)\s*/\s*(\d+)\s*\(([0-9.]+)%\)"
        ]
        
        for pattern in validity_patterns:
            match = re.search(pattern, summary_text)
            assert match, f"Validity pattern not found: {pattern}"
            
            valid_count = int(match.group(1))
            total_count = int(match.group(2))
            percentage = float(match.group(3))
            
            # Verify percentage calculation
            expected_pct = (valid_count / total_count) * 100
            assert abs(percentage - expected_pct) < 0.1, \
                   f"Percentage calculation error: {percentage}% vs expected {expected_pct}%"
        
        # Should have overall data quality percentage
        quality_match = re.search(r"Overall data quality:\s*([0-9.]+)%", summary_text)
        assert quality_match, "Overall data quality percentage not found"
        
        overall_quality = float(quality_match.group(1))
        assert 80 <= overall_quality <= 100, f"Overall quality {overall_quality}% seems unrealistic"


if __name__ == "__main__":
    # Run tests when executed directly
    pytest.main([__file__, "-v"])
